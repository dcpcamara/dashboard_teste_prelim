t2uf <- df4UFplot(df.prob.23_24, ano = 2023)
rio::export(t1uf, "data/t1uf.csv.gz")
rio::export(t2uf, "data/t2uf.csv.gz")
t1uf <- vroom::vroom("data/t1uf.csv.gz")
t2uf <- vroom::vroom("data/t2uf.csv.gz")
t1hd <- df4HDplot(df.prob.22_23, ano = 2022)
t2hd <- df4HDplot(df.prob.23_24, ano = 2023)
rio::export(t1hd, "data/t1hd.csv.gz")
rio::export(t2hd, "data/t2hd.csv.gz")
t1hd <- vroom::vroom("data/t1hd.csv.gz")
t2hd <- vroom::vroom("data/t2hd.csv.gz")
shiny::runApp()
shiny::runApp()
# source("aux_fun.r")
source("data_fun.r")
source("graf_fun.r")
pal <- met.brewer('Hiroshige', 5)[1:3]
pal2 <- c(met.brewer('Hiroshige', 7)[1], pal)
df.prob.22_23 <- read_csv(file = "samples/macro.prob.22_23.csv.gz")
df.prob.23_24 <- read_csv(file = "samples/macro.prob.23_24.csv.gz")
df.prob.24_25 <- read_csv(file = "samples/macro.prob.24_25.csv.gz")
t1br <- vroom::vroom("data/observed.csv.gz")
t2br <- vroom::vroom("data/observed.csv.gz")
t1uf <- vroom::vroom("data/t1uf.csv.gz")
t2uf <- vroom::vroom("data/t2uf.csv.gz")
t1hd <- vroom::vroom("data/t1hd.csv.gz")
t2hd <- vroom::vroom("data/t2hd.csv.gz")
plot_grafico_artigo(t1br, pal2)
t1br
t1uf
t1br
dengue.df <- vroom::vroom("data/cases.csv.gz")
spatial.tbl <- vroom::vroom("data/spatial.tbl.csv")
dengue.df <- dengue.df |>
left_join(spatial.tbl |>
select(geocode, uf, macroregional, macroregional_geocode),
by = c("municipio_geocodigo"="geocode") )
dados.macro <- dengue.df |>
prepare.data(suspected_cases = F)
prepare.data <- function(dado,
muncode = NULL,
suspected_cases = T # probable if FALSE
){
# Dado organizado por municipio e salvo em algum canto (formato fixo)
# > str(dengue.df)
# spc_tbl_ [2,709,420 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
# $ data_iniSE           : Date[1:2709420], format: "2025-02-02" "2025-02-02" "2025-02-02" ...
# $ municipio_geocodigo  : num [1:2709420] 1200104 1200054 1200401 1200708 1200203 ...
# $ casos_est            : num [1:2709420] 11 0 5372 10 129 ...
# $ casos_est_min        : num [1:2709420] 2 0 1662 1 11 ...
# $ casos_est_max        : num [1:2709420] 32 0 NA 70 1136 ...
# $ casos                : num [1:2709420] 0 0 141 0 1 0 0 19 0 0 ...
# $ ID_MN_RESI           : num [1:2709420] 120010 120005 120040 120070 120020 ...
# $ casos_prov           : num [1:2709420] 0 0 141 0 1 0 0 19 0 0 ...
# $ uf                   : chr [1:2709420] "AC" "AC" "AC" "AC" ...
# $ macroregional        : chr [1:2709420] "Acre" "Acre" "Acre" "Acre" ...
# $ macroregional_geocode: num [1:2709420] 1201 1201 1201 1201 1201 ...
# Define the outcome (Suspected or probable cases)
if(suspected_cases){
dado$cases = dado$casos
}else{
dado$cases = dado$casos_prov
}
# Filtering by municipality
if(!is.null(muncode)){
if(muncode > 999999){
aux <- dado |> filter(municipio_geocodigo == muncode)
}else{
aux <- dado |> filter(ID_MN_RESI == muncode)
}
aux$geocode = muncode
if(nrow(aux)==0){
stop("Invalid muncode.")
}
aux <- aux |>
transmute(
# uf = uf,
# macroregional = macroregional,
# macroregional_geocode = macroregional_geocode,
date = data_iniSE,
cases = cases,
geocode = geocode,
)
}
# By health macroregion (for a loop)
else{
aux <- dado |>
drop_na(uf, macroregional, macroregional_geocode) |>
group_by(uf, macroregional, macroregional_geocode, date = data_iniSE) |>
summarise(
cases = sum(cases)
) |>
mutate(
geocode = macroregional_geocode
)
}
aux <- aux %>%
mutate(
#Pop = Pop,
week = week.season(date),
# week = ifelse(week == 53, 52, week),
year = season(date),
target = F
)
# if(forecast.one.year.ahead){
#   aux.y = aux$year |> substr(start = 1, stop = 4) |> as.numeric() |> max()
#   new.season = season(epiweek = 1, epiyear = aux.y + 2)
#
#   aux <- aux |>
#     bind_rows(
#       tibble(
#         week = 1:52,
#         year = new.season,
#         target = T
#       )
#     )
# }
aux
}
dados.macro <- dengue.df |>
prepare.data(suspected_cases = F)
source("aux_fun.r")
source("data_fun.r")
source("graf_fun.r")
dengue.df <- vroom::vroom("data/cases.csv.gz")
spatial.tbl <- vroom::vroom("data/spatial.tbl.csv")
dengue.df <- dengue.df |>
left_join(spatial.tbl |>
select(geocode, uf, macroregional, macroregional_geocode),
by = c("municipio_geocodigo"="geocode") )
dados.macro <- dengue.df |>
prepare.data(suspected_cases = F)
season <- function(x, epiweek=NULL, epiyear=NULL, start = 41){
if( is.null(epiweek) | is.null(epiyear)){
if(!is.Date(x)) stop("Not Date format")
ew = epiweek(x)
ey = epiyear(x)
}else{
ew = epiweek
ey = epiyear
}
ifelse(ew < start, paste(ey-1, ey, sep = "-"), paste(ey, ey+1, sep = "-"))
}
week.season  <- function(x, epiweek=NULL, start = 41, week53 = T){
if( is.null(epiweek) ){
if(!is.Date(x)) stop("Not Date format")
ew = epiweek(x)
}else{
ew = epiweek
}
if(week53 & any(ew==53)) ew[ew==53] = 52
# 1 = start, 2 = start + 1, 3 = start + 2,...
ifelse(ew >= start, ew - start + 1, 52 - start + 1 + ew)
}
# Auxiliar functions
# Leo Bastos
get_cases <- function(
start_date=today()-11*7,
end_date = today(),
disease = 'dengue',
uf=NULL, # RJ
muncode=NULL, # 3304557
per_page = 100
){
infodengue_api <- "https://api.mosqlimate.org/api/datastore/infodengue/"
page <- "1"
pagination <- paste0("?page=", page, "&per_page=", per_page, "&")
filters <- paste0("disease=", disease, "&start=", start_date,
"&end=", end_date)
filters.extra <- case_when(
!is.null(muncode) ~  paste0("&geocode=", muncode),
(is.null(muncode) & !is.null(uf)) ~ paste0("&uf=", uf),
TRUE ~ NA
)
if(!is.na(filters.extra)){
filters <- paste0(filters, filters.extra)
}
url <- paste0(infodengue_api, pagination, filters)
resp <- GET(url)
content <- content(resp, "text")
json_content <- fromJSON(content)
items <- json_content$items
pagination_data <- json_content$pagination
PAGES <- pagination_data$total_pages
if(PAGES>1){
for(k in 2:PAGES){
pagination <- paste0("?page=", k, "&per_page=", per_page, "&")
json_content <- paste0(
infodengue_api,
pagination,
filters) |>
GET() |>
content("text") |>
fromJSON()
items.k <- json_content$items
items <- bind_rows(items, items.k)
}
}
items
}
# library(INLA)
# library(lubridate)
prepare.data <- function(dado,
muncode = NULL,
suspected_cases = T # probable if FALSE
){
# Dado organizado por municipio e salvo em algum canto (formato fixo)
# > str(dengue.df)
# spc_tbl_ [2,709,420 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
# $ data_iniSE           : Date[1:2709420], format: "2025-02-02" "2025-02-02" "2025-02-02" ...
# $ municipio_geocodigo  : num [1:2709420] 1200104 1200054 1200401 1200708 1200203 ...
# $ casos_est            : num [1:2709420] 11 0 5372 10 129 ...
# $ casos_est_min        : num [1:2709420] 2 0 1662 1 11 ...
# $ casos_est_max        : num [1:2709420] 32 0 NA 70 1136 ...
# $ casos                : num [1:2709420] 0 0 141 0 1 0 0 19 0 0 ...
# $ ID_MN_RESI           : num [1:2709420] 120010 120005 120040 120070 120020 ...
# $ casos_prov           : num [1:2709420] 0 0 141 0 1 0 0 19 0 0 ...
# $ uf                   : chr [1:2709420] "AC" "AC" "AC" "AC" ...
# $ macroregional        : chr [1:2709420] "Acre" "Acre" "Acre" "Acre" ...
# $ macroregional_geocode: num [1:2709420] 1201 1201 1201 1201 1201 ...
# Define the outcome (Suspected or probable cases)
if(suspected_cases){
dado$cases = dado$casos
}else{
dado$cases = dado$casos_prov
}
# Filtering by municipality
if(!is.null(muncode)){
if(muncode > 999999){
aux <- dado |> filter(municipio_geocodigo == muncode)
}else{
aux <- dado |> filter(ID_MN_RESI == muncode)
}
aux$geocode = muncode
if(nrow(aux)==0){
stop("Invalid muncode.")
}
aux <- aux |>
transmute(
# uf = uf,
# macroregional = macroregional,
# macroregional_geocode = macroregional_geocode,
date = data_iniSE,
cases = cases,
geocode = geocode,
)
}
# By health macroregion (for a loop)
else{
aux <- dado |>
drop_na(uf, macroregional, macroregional_geocode) |>
group_by(uf, macroregional, macroregional_geocode, date = data_iniSE) |>
summarise(
cases = sum(cases)
) |>
mutate(
geocode = macroregional_geocode
)
}
aux <- aux %>%
mutate(
#Pop = Pop,
week = week.season(date),
# week = ifelse(week == 53, 52, week),
year = season(date),
target = F
)
# if(forecast.one.year.ahead){
#   aux.y = aux$year |> substr(start = 1, stop = 4) |> as.numeric() |> max()
#   new.season = season(epiweek = 1, epiyear = aux.y + 2)
#
#   aux <- aux |>
#     bind_rows(
#       tibble(
#         week = 1:52,
#         year = new.season,
#         target = T
#       )
#     )
# }
aux
}
prepare.data.4.inla = function( dado, forecast.one.year.ahead = T ){
# Dado - output of prepare.data filtered for only one region
if(length(unique(dado$geocode)) != 1){
stop("There are more than one geocode in the data")
}
if(forecast.one.year.ahead){
aux.y = dado$year |> substr(start = 1, stop = 4) |> as.numeric() |> max()
new.season = season(epiweek = 1, epiyear = aux.y + 2)
suppressWarnings(
aux <- dado |>
bind_rows(
tibble(
week = 1:52,
year = new.season,
geocode = dado$geocode[1],
target = T
)
)
)
}
aux
}
forecasting.inla <- function(data.inla,   # dados - Data containing columns (geocode, cases, week, year, target)
#Year2forecast = 2023,
MC = FALSE, M = 2000,
# Changing the first week and redefine year as seasons
start = 41,
# make week 53 as week 52 (POG!)
week53 = T,
quantiles = c(0.05, 0.25, 0.5, 0.75, 0.9, 0.95),
output.only = F,
likelihood = "nbinomial",
timeRE = "rw2",
cyclic = T,
WAIC = F){
formula.q <- cases ~ 1 +
f(week, model = timeRE, constr = T, cyclic = cyclic,
hyper = list(
# Precision of unstructure random effects
prec = list(
prior="pc.prec",
param=c(3, 0.01)
)
)
) +
f(year, model = "iid", constr = T,
hyper = list(
# Precision of unstructure random effects
prec = list(
prior="pc.prec",
param=c(3, 0.01)
)
)
)
# # Adding forecasting component
# data.inla <- data.inla %>%
#   add_row(week = 1:52, Year = Year2forecast) %>%
#   mutate(year = Year - min(Year) + 1)
linear.term.year.cur <- which(data.inla$target == T)
output.mean <- inla(formula = formula.q,
data = data.inla %>%
mutate(
cases = ifelse(target==F, cases, NA)
),
control.predictor = list(link = 1, compute = T,
quantiles = quantiles),
family = likelihood,
# offset = log(Pop / 1e5),
# control.family = list(
#   control.link = list(
#     model = "quantile",
#     quantile = 0.5
#     )
#   ),
# control.fixed = control.fixed(prec.intercept = 1),
control.compute = list(config = MC, waic = WAIC)
)
out = NULL
out$inla = output.mean
out$pred = data.inla %>% ungroup() |> filter(target == T) %>% select(geocode, week, year) |>
bind_cols( output.mean$summary.fitted.values[linear.term.year.cur,] )
if(MC){
param.samples <- inla.posterior.sample(output.mean, n = M)
samples.MC <- param.samples %>%
map(.f = function(xxx, idx = linear.term.year.cur){
rnbinom(
n = idx,
mu = exp(xxx$latent[idx]),
size = xxx$hyperpar[1]
)} )
names(samples.MC) <- 1:M
samples.MC <- samples.MC %>%
bind_rows(.id = "samples") %>%
rowid_to_column(var = "week") %>%
gather(key = "samples", value = "values", -week)
out$MC = samples.MC
}
out
}
output.treat.macro = function(x, UF, geocode){
x$pred$uf = UF
x$pred$macrocode = geocode
x$MC$uf = UF
x$MC$macrocode = geocode
x
}
threshold.MC <- function(samples.MC){
thresholdw.data <- samples.MC %>%
group_by(week) %>%
summarise(
Q1 = quantile(probs = 0.25, values),
Q2 = quantile(probs = 0.50, values),
Q3 = quantile(probs = 0.75, values),
P90 = quantile(probs = 0.9, values),
)
thresholdw.data
}
season <- function(x, epiweek=NULL, epiyear=NULL, start = 41){
if( is.null(epiweek) | is.null(epiyear)){
if(!is.Date(x)) stop("Not Date format")
ew = epiweek(x)
ey = epiyear(x)
}else{
ew = epiweek
ey = epiyear
}
ifelse(ew < start, paste(ey-1, ey, sep = "-"), paste(ey, ey+1, sep = "-"))
}
# season(today())
week.season  <- function(x, epiweek=NULL, start = 41, week53 = T){
if( is.null(epiweek) ){
if(!is.Date(x)) stop("Not Date format")
ew = epiweek(x)
}else{
ew = epiweek
}
if(week53 & any(ew==53)) ew[ew==53] = 52
# 1 = start, 2 = start + 1, 3 = start + 2,...
ifelse(ew >= start, ew - start + 1, 52 - start + 1 + ew)
}
# Funcao auxiliar para rodar os tres cenarios
run_inla_forecasting = function(dados, macro, uf){
aux = forecasting.inla(dados = dados, MC =T)
aux$pred$uf = uf
aux$pred$macrocode = macro
aux$MC$uf = uf
aux$MC$macrocode = macro
aux
}
dados.macro <- dengue.df |>
prepare.data(suspected_cases = F)
observed <- dados.macro |>
rename(season = year) |>
mutate(year.s.first = as.numeric(str_sub(season, 1, 4))) |>
filter(season >= 2022)
rio::export(observed, "data/observed.csv.gz")
observed <- vroom::vroom("data/observed.csv.gz")
observed
df4BRplot <- function(obj, ano) {
observed.tmp <- observed |>
filter(year.s.first == ano) |>
group_by(week, season, year.s.first, date) |>
summarise(cases = sum(cases, na.rm = TRUE))
temp <- obj |>
group_by(week, samples) |>
summarise(values = sum(values)) |>
ungroup() |>
group_by(week) |>
summarise(q50 = quantile(values, probs = 0.5),
q75 = quantile(values, probs = 0.75),
q90 = quantile(values, probs = 0.9),
q100 = Inf)
tmp1 <- temp |>
pivot_longer(
cols = c(q50, q75, q90, q100),
names_to = 'quantile',
values_to = 'maxvalues'
)
tmp2 <- temp |>
mutate(q100 = q90,
q90 = q75,
q75 = q50,
q50 = 0) |>
pivot_longer(
cols = c(q50, q75, q90, q100),
names_to = 'quantile',
values_to = 'minvalues'
)
tmp <- tmp1 |>
left_join(tmp2, by = c('week', 'quantile')) |>
ungroup() |>
left_join(observed.tmp, by = 'week') |>
mutate(epiweek = ifelse(week <= 12, yes = week + 40, no = week -12),
epiyear = ifelse(week <= 12, yes = ano, no = ano + 1),
date = aweek::get_date(week = epiweek, year = epiyear,start = 7))
tmp$quantile <- factor(tmp$quantile,
levels = c('q50','q75','q90','q100'),
labels = c('Below the median,\ntypical','Moderately high,\nfairly typical',
'Fairly high,\natypical', 'Exceptionally high,\nvery atypical'))
return(tmp)
}
t1br <- df4BRplot(df.prob.22_23, ano = 2022)
t2br <- df4BRplot(df.prob.23_24, ano = 2023)
t1br
t2br
rio::export(t1br, "data/t1br.csv.gz")
rio::export(t2br, "data/t2br.csv.gz")
t1br <- vroom::vroom("data/t1br.csv.gz")
t2br <- vroom::vroom("data/t2br.csv.gz")
sort(unique(observed$uf))
runApp()
runApp()
shiny::runApp()
?seq_along
library(tidyverse)
?layout
runApp()
?add_trace
pal <- met.brewer('Hiroshige', 5)[1:3]
shiny::runApp()
shiny::runApp()
shiny::runApp()
rio::import("data/observed.csv.gz")
?read_csv
import(file = "samples/macro.prob.22_23.csv.gz")
runApp()
shiny::runApp()
rsconnect::showLogs()
list.files(".")
runApp()
